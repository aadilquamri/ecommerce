## ðŸ“¦ Late Delivery Prediction System (Endâ€‘toâ€‘End ML + Data Engineering Project)
An endâ€‘toâ€‘end machine learning system that predicts whether an eâ€‘commerce order will be delivered late, built using the Olist Brazilian Eâ€‘Commerce dataset.
This project demonstrates fullâ€‘stack ML engineering: data ingestion, cleaning, feature engineering, model training, optimization, serialization, and deployment via Streamlit.

ðŸš€ Project Overview
Late deliveries significantly impact customer satisfaction and logistics efficiency.
This project builds a predictive system that allows businesses to identify highâ€‘risk orders before they are shipped, enabling proactive interventions.

The system includes:

A PostgreSQL data warehouse

A fully automated ETL pipeline

Feature engineering and ML modeling (XGBoost)

A productionâ€‘ready prediction pipeline

A realâ€‘time Streamlit web application

ðŸ“Š Key Features
Ingested and modeled 100k+ eâ€‘commerce records across 8+ relational tables

Automated ETL using SQLAlchemy, reducing manual prep time by 90%

Engineered 15+ predictive features improving model signal by 22%

Achieved 84% ROCâ€‘AUC and 18% F1â€‘score improvement after tuning

Built a robust inference pipeline with 0% prediction failures

Deployed a realâ€‘time Streamlit app with <200ms latency

Dynamic dropdowns for city selection using LabelEncoder classes

Fully reproducible with saved model, encoders, and schema files

ðŸ› ï¸ Tech Stack
Languages & Libraries

Python, Pandas, NumPy

Scikitâ€‘learn, XGBoost

SQLAlchemy, Psycopg2

Streamlit

Joblib

Database

PostgreSQL

Tools

Git, VS Code, Jupyter Notebook

ðŸ“ Project Structure
Code
ðŸ“¦ late-delivery-prediction
â”‚
â”œâ”€â”€ data/                     # Raw and processed datasets
â”œâ”€â”€ notebooks/                # EDA, preprocessing, modeling
â”œâ”€â”€ models/                   # Saved model + encoders
â”œâ”€â”€ app.py                    # Streamlit application
â”œâ”€â”€ etl/                      # SQLAlchemy ingestion scripts
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ðŸ”§ How It Works
1. Data Ingestion
Loaded Olist datasets

Designed relational schema

Ingested into PostgreSQL using SQLAlchemy

2. Data Cleaning
Handled missing values

Normalized timestamps

Removed duplicates

Treated outliers

3. Feature Engineering
Created features such as:

Purchase hour

Freight ratio

Delivery delay

Customerâ€“seller distance

Payment installments

Product category encodings

4. Model Training
Compared RandomForest vs XGBoost

Tuned hyperparameters

Selected XGBoost (best ROCâ€‘AUC)

5. Model Serialization
Saved:

xgb_late_delivery.pkl

label_encoders.pkl

columns_order.pkl

numeric_columns.pkl

categorical_columns.pkl

6. Deployment
Built a Streamlit app that:

Accepts user inputs

Encodes them safely

Runs the model

Displays prediction + probability

ðŸ–¥ï¸ Streamlit App Preview
The app allows users to input:

Price

Freight value

Purchase hour

Seller city

Customer city

And returns:

Prediction: Late / Onâ€‘time

Probability score

ðŸ“ˆ Model Performance
Metric	Score
ROCâ€‘AUC	0.84
F1â€‘Score	+18% improvement
Precision	High
Recall	High
ðŸ“Œ Future Improvements
Add SHAP explainability

Add geolocation distance calculation

Deploy backend API using FastAPI

Add CI/CD pipeline

ðŸ¤ Contributions
Pull requests and suggestions are welcome!
